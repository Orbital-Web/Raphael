# Raphael NNUE

This document contains all the information for the various Raphael NNUE iterations.

## Raphael 2.0

### Basilisk v1

**Architecture:** `(768 -> 64) x2 -> 1`

**Quantization:** `QA=255, QB=64`

**Training Parameters:**

```text
lr:  linear-decay from 0.001 to 0.001 * 0.3^5
wdl: 0.3
```

**Notes:**
> This is the very first Raphael NNUE, and it was trained using a custom datagen script and a custom trainer written using Pytorch.
>
> The data was generated by evaluating around 200 million positions from public CCRL matches at 5000 softnodes using Raphael v1.8 (HCE). Then, positions in check and positions where the bestmove is a capture were filtered out, leaving around 150 million positions.

## Raphael 3.1

### Basilisk v2

**Training Parameters:**

```text
lr:  cosine-decay from 0.001 to 0.001 * 0.3^5
wdl: 0.4
```

**Notes:**
> Same arch as v1, but data comes from self-played games at 5000 softnodes. Postions were filtered using the default viriformat filter in bullet, but with `min_pieces=2`.
>
> Around 6m games were played with around 600m positions pre-filtering. The net was trained using bullet with basically the same settings as 1-simple.rs, apart from a few training and model parameters.
